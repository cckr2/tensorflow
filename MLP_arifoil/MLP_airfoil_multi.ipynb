{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self,data_file, log_file, save_file, hidden_node_num):\n",
    "        #Define instance variable\n",
    "        self.__data_file = data_file\n",
    "        self.__log_file = log_file\n",
    "        self.__save_file = save_file\n",
    "        self.__log = None\n",
    "\n",
    "        self.__hidden_node_num = hidden_node_num\n",
    "        \n",
    "        self.x_train_data = None\n",
    "        self.y_train_data = None\n",
    "        self.x_test_data = None\n",
    "        self.y_test_data = None\n",
    "        self.__x_data_len = None\n",
    "        \n",
    "        self.__y = None\n",
    "        self.__x = None\n",
    "        \n",
    "        self.__w1 = None\n",
    "        self.__w2 = None\n",
    "        self.__b1 = None\n",
    "        self.__b2 = None\n",
    "        self.__cost = None\n",
    "        \n",
    "        self.__y_out = None\n",
    "        self.__train = None\n",
    "        self.__sess = None\n",
    "        self.__saver = None\n",
    "        \n",
    "        self.__loadData()\n",
    "        self.__init_model()\n",
    "        \n",
    "    def __loadData(self):\n",
    "        #Read data file\n",
    "        data_file_name = self.__data_file\n",
    "        xy = np.genfromtxt(data_file_name, dtype='float32')\n",
    "        \n",
    "        #Shuffle data\n",
    "        np.random.shuffle(xy)\n",
    "        \n",
    "        #Data Split into train data and test data\n",
    "        all_data_num = xy[:,1:-1].shape[0]\n",
    "        train_data_num = int(all_data_num * 95 /100)\n",
    "        test_data_num = all_data_num - train_data_num\n",
    "        self.x_train_data =  xy[:train_data_num,1:-1]\n",
    "        self.y_train_data =  xy[:train_data_num,-1]\n",
    "        self.x_test_data =  xy[train_data_num:,1:-1]\n",
    "        self.y_test_data =  xy[train_data_num:,-1]\n",
    "\n",
    "        #Transpose Matrix having x_data\n",
    "        self.x_train_data = self.x_train_data.transpose()\n",
    "        self.x_test_data = self.x_test_data.transpose()\n",
    "\n",
    "        #Calculate num of variable\n",
    "        self.__x_data_len = len(self.x_train_data)\n",
    "        \n",
    "    def __init_model(self):\n",
    "        self.__x = tf.placeholder(dtype=tf.float32)\n",
    "        self.__y = tf.placeholder(dtype=tf.float32)\n",
    "        \n",
    "        # setup hidden layer1\n",
    "        self.__w1 = tf.Variable(tf.random_normal([self.__hidden_node_num, self.__x_data_len]), name='w1')\n",
    "        self.__b1 = tf.Variable(tf.random_normal([self.__hidden_node_num, 1]), name='b1')\n",
    "        hidden_layer1 = tf.nn.sigmoid(tf.matmul(self.__w1, self.__x ) + self.__b1)\n",
    "        \n",
    "        # setup output layer\n",
    "        self.__w2 = tf.Variable(tf.random_normal([1,self.__hidden_node_num]),name='w2')\n",
    "        self.__b2 = tf.Variable(tf.random_normal([1,1]), name='b2')\n",
    "        self.__y_out = tf.matmul(self.__w2,hidden_layer1) + self.__b2\n",
    "        \n",
    "        # setup cost function and optimizer\n",
    "        self.__cost = tf.reduce_mean(tf.square(self.__y_out-  self.__y))\n",
    "        opt = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "        # self.__cost = tf.nn.l2_loss(self.__y_out-self.__y)\n",
    "        # opt= tf.train.AdamOptimizer(0.1)\n",
    "        self.__train = opt.minimize(self.__cost)\n",
    "    \n",
    "    def init_sess(self):\n",
    "        init = tf.global_variables_initializer()\n",
    "        self.__sess = tf.Session()\n",
    "        self.__sess.run(init)\n",
    "        \n",
    "        if self.__save_file != None:\n",
    "            self.__saver = tf.train.Saver()\n",
    "            \n",
    "        if self.__log_file != None:\n",
    "            self.__log = open(self.__log_file,'w')\n",
    "            self.__log.write(\"Step\\tTraning Cost\\tTest Accuracy\\n\")\n",
    "            self.__log.close()\n",
    "        \n",
    "    def model_train(self):\n",
    "        self.__sess.run(self.__train,feed_dict={self.__x: self.x_test_data, self.__y: self.y_test_data})\n",
    "        \n",
    "    def model_save(self):\n",
    "        if self.__save_file != None:\n",
    "            self.__saver.save(self.__sess, self.__save_file)\n",
    "\n",
    "    def log_write(self, num):\n",
    "        if self.__log_file != None:\n",
    "            predic = self.__sess.run(self.__y_out,feed_dict={self.__x: self.x_test_data})\n",
    "            result = (self.y_test_data- predic) /predic * 100\n",
    "            self.__log = open(self.__log_file,'a')\n",
    "            self.__log.write(str(num) + \"\\t\")\n",
    "            self.__log.write(str(self.__sess.run(self.__cost,feed_dict={self.__x: self.x_test_data,self.__y: self.y_test_data}))+ \"\\t\")\n",
    "            self.__log.write(str(np.mean(result))+ \"\\n\")\n",
    "            self.__log.close()\n",
    "        \n",
    "    def close(self):\n",
    "        self.__sess.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_node_num = 10;\n",
    "train_num = 25000\n",
    "print_inter = 5000 \n",
    "alpha_num = 1\n",
    "start_alpha = 0\n",
    "end_alpha = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nowDatetime = datetime.datetime.now().strftime('%m%d_%H%M')\n",
    "logDir = \"log/\" + nowDatetime\n",
    "saveDir= \"model/\" + nowDatetime\n",
    "if not os.path.exists(logDir):\n",
    "    os.makedirs(logDir)\n",
    "    \n",
    "if not os.path.exists(saveDir):\n",
    "    os.makedirs(saveDir)    \n",
    "\n",
    "model_array = []\n",
    "\n",
    "for i in range(start_alpha,end_alpha+1):\n",
    "    dataPath = \"data/data_Alpha_\" + str(i) + \".txt\"\n",
    "    logPath = logDir + \"/log_\" + str(i) +\".txt\"\n",
    "    savePath = saveDir  + \"/model_\" + str(i)\n",
    "    model_array.append(MLP(dataPath, logPath, savePath,hidden_node_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning Start\n",
      "Step :  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Traning Start\")\n",
    "\n",
    "for i in range(alpha_num):\n",
    "    model_array[i].init_sess()\n",
    "    \n",
    "for step in range(train_num):\n",
    "    for i in range(alpha_num):\n",
    "        model_array[i].model_train()\n",
    "    if step%print_inter == 0:\n",
    "        print(\"Step : \",step)\n",
    "        for i in range(alpha_num):\n",
    "            model_array[i].log_write(step)\n",
    "            model_array[i].model_save()\n",
    "            \n",
    "for i in range(alpha_num):            \n",
    "    model_array[i].log_write(step)\n",
    "    model_array[i].model_save()            \n",
    "    model_array[i].close()\n",
    "    \n",
    "print(\"Traning Finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
